{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b220ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyaudio in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (0.2.14)\n",
      "Requirement already satisfied: librosa in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: torch in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in d:\\anaconda\\lib\\site-packages (from librosa) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in d:\\anaconda\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\anaconda\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in d:\\anaconda\\lib\\site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in d:\\anaconda\\lib\\site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in d:\\anaconda\\lib\\site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\anaconda\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio librosa transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ea7e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(duration, output_filename):\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 1\n",
    "    fs = 44100  \n",
    "    # Record at 44100 samples per second\n",
    "\n",
    "    p = pyaudio.PyAudio()  \n",
    "    # Create an interface to PortAudio\n",
    "\n",
    "    print('Recording')\n",
    "\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "\n",
    "    frames = []  \n",
    "    # Initialize array to store frames\n",
    "\n",
    "    # Store data in chunks for the specified duration\n",
    "    for i in range(0, int(fs / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "\n",
    "    print('Finished recording')\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open(output_filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "record_audio(10, 'output.wav')  # Record audio for 10 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4825eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=16000)\n",
    "    return audio, sr\n",
    "\n",
    "audio, sr = load_audio('output.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1c5042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def speech_to_text(audio, sr):\n",
    "    inputs = processor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    return transcription[0]\n",
    "\n",
    "transcription = speech_to_text(audio, sr)\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73f7a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36561cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2bca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\rithe\\appdata\\roaming\\python\\python311\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447c3c43",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2454787082.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    for n in range(5):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm \n",
    "s = spm.SentencePieceProcessor(model_file='spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a06b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cefa48e9b04e3390bef3b720f5a899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rithe\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7386d6dc5a49b1b7c1040b529d7d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653e6601a2d242dabc62b848f3b1905e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ebc37832a040cbbdee59f8ed460dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a07712e9304a1ea5aee214f4d41393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a a a a a a a a a a a a a a a a a a a a.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "summary = summarize_text(transcription)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b41376",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    duration = 10  # Duration in seconds\n",
    "    output_filename = 'output.wav'\n",
    "\n",
    "    # Step 1: Record Audio\n",
    "    record_audio(duration, output_filename)\n",
    "\n",
    "    # Step 2: Load and Preprocess Audio\n",
    "    audio, sr = load_audio(output_filename)\n",
    "\n",
    "    # Step 3: Convert Speech to Text\n",
    "    transcription = speech_to_text(audio, sr)\n",
    "    print(\"Transcription:\", transcription)\n",
    "\n",
    "    # Step 4: Summarize Text\n",
    "    summary = summarize_text(transcription)\n",
    "    print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5662e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wxpython\n",
      "  Obtaining dependency information for wxpython from https://files.pythonhosted.org/packages/36/60/0e40b653df66328e53c60d69c4f6c835655837e89da42e95feb28aa18118/wxPython-4.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wxPython-4.2.1-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pillow in d:\\anaconda\\lib\\site-packages (from wxpython) (10.3.0)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from wxpython) (1.16.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from wxpython) (1.24.3)\n",
      "Downloading wxPython-4.2.1-cp311-cp311-win_amd64.whl (17.8 MB)\n",
      "   ---------------------------------------- 0.0/17.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/17.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/17.8 MB 495.5 kB/s eta 0:00:36\n",
      "    --------------------------------------- 0.4/17.8 MB 3.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.3/17.8 MB 7.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.4/17.8 MB 10.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 3.0/17.8 MB 11.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.4/17.8 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.7/17.8 MB 13.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.6/17.8 MB 13.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 6.6/17.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 7.3/17.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 8.0/17.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 8.7/17.8 MB 15.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 9.5/17.8 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 10.1/17.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 11.1/17.8 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.1/17.8 MB 17.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 13.0/17.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 14.3/17.8 MB 19.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 14.5/17.8 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.8/17.8 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.8/17.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 15.2/17.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 15.7/17.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 15.9/17.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 16.2/17.8 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 16.6/17.8 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.0/17.8 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.0/17.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.6/17.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/17.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/17.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/17.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/17.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 17.8/17.8 MB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: wxpython\n",
      "Successfully installed wxpython-4.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts helpviewer.exe, img2png.exe, img2py.exe, img2xpm.exe, pycrust.exe, pyshell.exe, pyslices.exe, pyslicesshell.exe, pywxrc.exe, wxdemo.exe, wxdocs.exe and wxget.exe are installed in 'C:\\Users\\rithe\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install wxpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wx\n",
    "import threading\n",
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained models and processors\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "summary_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "class SpeechToTextApp(wx.Frame):\n",
    "    def __init__(self, *args, **kw):\n",
    "        super(SpeechToTextApp, self).__init__(*args, **kw)\n",
    "\n",
    "        self.InitUI()\n",
    "        self.Bind(wx.EVT_CLOSE, self.OnClose)\n",
    "\n",
    "    def InitUI(self):\n",
    "        panel = wx.Panel(self)\n",
    "\n",
    "        vbox = wx.BoxSizer(wx.VERTICAL)\n",
    "\n",
    "        # Record Button\n",
    "        self.record_button = wx.Button(panel, label='Record')\n",
    "        self.record_button.Bind(wx.EVT_BUTTON, self.OnRecord)\n",
    "        vbox.Add(self.record_button, flag=wx.EXPAND|wx.LEFT|wx.RIGHT|wx.TOP, border=10)\n",
    "\n",
    "        # Convert Button\n",
    "        self.convert_button = wx.Button(panel, label='Convert')\n",
    "        self.convert_button.Bind(wx.EVT_BUTTON, self.OnConvert)\n",
    "        self.convert_button.Disable()\n",
    "        vbox.Add(self.convert_button, flag=wx.EXPAND|wx.LEFT|wx.RIGHT|wx.TOP, border=10)\n",
    "\n",
    "        # Text Display\n",
    "        self.text_ctrl = wx.TextCtrl(panel, style=wx.TE_MULTILINE|wx.TE_READONLY)\n",
    "        vbox.Add(self.text_ctrl, proportion=1, flag=wx.EXPAND|wx.LEFT|wx.RIGHT|wx.TOP, border=10)\n",
    "\n",
    "        panel.SetSizer(vbox)\n",
    "\n",
    "        self.SetSize((400, 300))\n",
    "        self.SetTitle('Speech to Text App')\n",
    "        self.Centre()\n",
    "\n",
    "    def OnRecord(self, event):\n",
    "        self.record_button.Disable()\n",
    "        self.text_ctrl.SetValue(\"Recording...\")\n",
    "        threading.Thread(target=self.record_audio, args=(10, 'output.wav')).start()\n",
    "\n",
    "    def OnConvert(self, event):\n",
    "        self.convert_button.Disable()\n",
    "        self.text_ctrl.SetValue(\"Converting...\")\n",
    "        threading.Thread(target=self.process_audio).start()\n",
    "\n",
    "    def record_audio(self, duration, output_filename):\n",
    "        chunk = 1024\n",
    "        sample_format = pyaudio.paInt16\n",
    "        channels = 1\n",
    "        fs = 44100\n",
    "\n",
    "        p = pyaudio.PyAudio()\n",
    "\n",
    "        stream = p.open(format=sample_format,\n",
    "                        channels=channels,\n",
    "                        rate=fs,\n",
    "                        frames_per_buffer=chunk,\n",
    "                        input=True)\n",
    "\n",
    "        frames = []\n",
    "\n",
    "        for _ in range(0, int(fs / chunk * duration)):\n",
    "            data = stream.read(chunk)\n",
    "            frames.append(data)\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        with wave.open(output_filename, 'wb') as wf:\n",
    "            wf.setnchannels(channels)\n",
    "            wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "            wf.setframerate(fs)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "\n",
    "        wx.CallAfter(self.OnRecordComplete)\n",
    "\n",
    "    def OnRecordComplete(self):\n",
    "        self.text_ctrl.SetValue(\"Recording complete. Click 'Convert' to process the audio.\")\n",
    "        self.convert_button.Enable()\n",
    "\n",
    "    def process_audio(self):\n",
    "        audio, sr = librosa.load('output.wav', sr=16000)\n",
    "        transcription = self.speech_to_text(audio, sr)\n",
    "        summary = self.summarize_text(transcription)\n",
    "        wx.CallAfter(self.OnConvertComplete, transcription, summary)\n",
    "\n",
    "    def speech_to_text(self, audio, sr):\n",
    "        inputs = processor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs.input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)\n",
    "        return transcription[0]\n",
    "\n",
    "    def summarize_text(self, text):\n",
    "        inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        summary_ids = summary_model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "\n",
    "    def OnConvertComplete(self, transcription, summary):\n",
    "        self.text_ctrl.SetValue(f\"Transcription:\\n{transcription}\\n\\nSummary:\\n{summary}\")\n",
    "        self.record_button.Enable()\n",
    "        self.convert_button.Disable()\n",
    "\n",
    "    def OnClose(self, event):\n",
    "        self.Destroy()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = wx.App()\n",
    "    ex = SpeechToTextApp(None)\n",
    "    ex.Show()\n",
    "    app.MainLoop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37715318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
